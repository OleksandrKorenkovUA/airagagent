# –Ü–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫ –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ Milvus - –≤–µ–∫—Ç–æ—Ä–Ω–æ—é –±–∞–∑–æ—é –¥–∞–Ω–∏—Ö –¥–ª—è –ø–æ—à—É–∫—É —Å—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
from milvus_model.hybrid import BGEM3EmbeddingFunction
import re # –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–Ω–∏—Ö –≤–∏—Ä–∞–∑—ñ–≤
import subprocess
import numpy as np
from pymilvus import Collection

import torch
torch.classes.__path__ = []
import subprocess
from langchain_huggingface.llms import HuggingFacePipeline
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
# –Ü–º–ø–æ—Ä—Ç –±—ñ–±–ª—ñ–æ—Ç–µ–∫ –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ LLM (–≤–µ–ª–∏–∫–∏–º–∏ –º–æ–≤–Ω–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏)
from PIL import Image  # –î–ª—è –æ–±—Ä–æ–±–∫–∏ –∑–æ–±—Ä–∞–∂–µ–Ω—å
from langchain_ollama import ChatOllama  # –î–ª—è –≤–∑–∞—î–º–æ–¥—ñ—ó –∑ Ollama API
from langchain_core.prompts import ChatPromptTemplate  # –î–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —à–∞–±–ª–æ–Ω—ñ–≤ –ø—Ä–æ–º–ø—Ç—ñ–≤
from langchain_text_splitters import RecursiveCharacterTextSplitter  # –î–ª—è —Ä–æ–∑–±–∏—Ç—Ç—è —Ç–µ–∫—Å—Ç—É –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
# –Ü–º–ø–æ—Ä—Ç –¥–ª—è —Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ—à—É–∫—É
from pymilvus.model.reranker import BGERerankFunction  # –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –ø–µ—Ä–µ—Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ—à—É–∫—É
# –Ü–º–ø–æ—Ä—Ç –¥–ª—è –æ–±—Ä–æ–±–∫–∏ —Ç–µ–∫—Å—Ç—É —Ç–∞ –∑–æ–±—Ä–∞–∂–µ–Ω—å
from transformers import pipeline as hf_pipeline  # –ö–æ–Ω–≤–µ—î—Ä –¥–ª—è –æ–±—Ä–æ–±–∫–∏ —Ç–µ–∫—Å—Ç—É —Ç–∞ –∑–æ–±—Ä–∞–∂–µ–Ω—å
# –Ü–º–ø–æ—Ä—Ç –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ —Ä—ñ–∑–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤
import soundfile as sf  # –î–ª—è —á–∏—Ç–∞–Ω–Ω—è PDF-—Ñ–∞–π–ª—ñ–≤
from PyPDF2 import PdfReader  # –î–ª—è —á–∏—Ç–∞–Ω–Ω—è PDF-—Ñ–∞–π–ª—ñ–≤
from docx import Document as DocxDocument  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ Word-–¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
# –Ü–º–ø–æ—Ä—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫ Python
from datetime import datetime as dt  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –¥–∞—Ç–æ—é —Ç–∞ —á–∞—Å–æ–º
from pathlib import Path  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ —à–ª—è—Ö–∞–º–∏ —Ñ–∞–π–ª—ñ–≤
from typing import Any, Dict  # –î–ª—è —Ç–∏–ø—ñ–∑–∞—Ü—ñ—ó
import re  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ —Ä–µ–≥—É–ª—è—Ä–Ω–∏–º–∏ –≤–∏—Ä–∞–∑–∞–º–∏
import logging  # –î–ª—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
import streamlit as st  # –î–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤–µ–±-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
import ollama  # –î–ª—è –≤–∑–∞—î–º–æ–¥—ñ—ó –∑ Ollama API
import json  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ JSON
import yt_dlp  # –î–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—ñ–¥–µ–æ –∑ YouTube
import hashlib  # –î–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ö–µ—à—ñ–≤
import whisper  # –î–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü—ñ—ó –∞—É–¥—ñ–æ
import os  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –æ–ø–µ—Ä–∞—Ü—ñ–π–Ω–æ—é —Å–∏—Å—Ç–µ–º–æ—é
import uuid  # –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤
import pandas as pd  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ —Ç–∞–±–ª–∏—á–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
import base64  # –î–ª—è –∫–æ–¥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö —É base64
import io  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –ø–æ—Ç–æ–∫–∞–º–∏ –≤–≤–µ–¥–µ–Ω–Ω—è-–≤–∏–≤–µ–¥–µ–Ω–Ω—è
import sqlite3  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ SQLite –±–∞–∑–∞–º–∏ –¥–∞–Ω–∏—Ö
from tqdm import tqdm  # –î–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É
from datetime import datetime  # –î–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –¥–∞—Ç–æ—é —Ç–∞ —á–∞—Å–æ–º
from config import *  # –Ü–º–ø–æ—Ä—Ç –≤—Å—ñ—Ö –∑–º—ñ–Ω–Ω–∏—Ö –∑ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
from rag import *  # –Ü–º–ø–æ—Ä—Ç –≤—Å—ñ—Ö —Ñ—É–Ω–∫—Ü—ñ–π –∑ —Ñ–∞–π–ª—É rag.py
# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è —Ä–æ–±–æ—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º–∏
logger = logging.getLogger(__name__)

if 'chunk_size' not in st.session_state or st.session_state.chunk_size is None:
    st.session_state.chunk_size = CHUNK_SIZE
if 'chunk_overlap' not in st.session_state or st.session_state.chunk_overlap is None:
    st.session_state.chunk_overlap = OVERLAP
if 'ret_k_results' not in st.session_state or st.session_state.ret_k_results is None:
    st.session_state.ret_k_results = RET_K_RESULTS


# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥–µ–ª—ñ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –µ–º–±–µ–¥—ñ–Ω–≥—ñ–≤ (–≤–µ–∫—Ç–æ—Ä–Ω–∏—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—å) —Ç–µ–∫—Å—Ç—É
EMBEDDER = BGEM3EmbeddingFunction(
    model_name=EMBEDING_MODEL,  # –ù–∞–∑–≤–∞ –º–æ–¥–µ–ª—ñ –¥–ª—è –µ–º–±–µ–¥—ñ–Ω–≥—ñ–≤
    device="cuda" if torch.cuda.is_available() else "cpu",        # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CPU –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω—å (–Ω–∞–π–±–µ–∑–ø–µ—á–Ω—ñ—à–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç)
    use_fp16=False       # –í—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–æ–ª–æ–≤–∏–Ω–Ω–æ—ó —Ç–æ—á–Ω–æ—Å—Ç—ñ (fp16)
)

def reset_chat():
    """–°–∫–∏–¥–∞—î —ñ—Å—Ç–æ—Ä—ñ—é —á–∞—Ç—É –≤ —Å–µ—Å—ñ—ó Streamlit, –≤–∏–¥–∞–ª—è—é—á–∏ –≤—Å—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —Ç–∞ —Å—Ç–∞–Ω –ø—Ä–∏–≤—ñ—Ç–∞–Ω–Ω—è"""
    st.session_state.messages      = []  # –û—á–∏—â–µ–Ω–Ω—è —Å–ø–∏—Å–∫—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
    st.session_state.chat_history  = []  # –û—á–∏—â–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó —á–∞—Ç—É
    st.session_state.pop("greeted", None)  # –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞–Ω—É –ø—Ä–∏–≤—ñ—Ç–∞–Ω–Ω—è


# —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è –¥—É–∂–æ–∫ –∑ —Ç–µ–∫—Å—Ç—É
def remove_think(text):
    return re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL) if '<think>' in text else text


def create_bge_m3_embeddings():
    """–°—Ç–≤–æ—Ä—é—î —Ñ—É–Ω–∫—Ü—ñ—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –µ–º–±–µ–¥—ñ–Ω–≥—ñ–≤ BGE-M3, –ø–æ–≤–µ—Ä—Ç–∞—é—á–∏ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π –æ–±'—î–∫—Ç EMBEDDER"""
    bge_m3_ef = EMBEDDER  # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –æ–±'—î–∫—Ç–∞ EMBEDDER
    return bge_m3_ef

    
@st.cache_resource(show_spinner="–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —É–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω—É –º–æ–¥–µ–ª—å‚Ä¶")
def create_ukr_llm():
    model_id = UKRAINIAN_MODEL
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        device_map="auto",      
        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32
    )
    return pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=MAX_TOKENS,
        do_sample=False,
    )


def create_llm(model_name):
    """–°—Ç–≤–æ—Ä—é—î –µ–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª—ñ LLM –∑ –≤–∫–∞–∑–∞–Ω–æ—é –Ω–∞–∑–≤–æ—é, –Ω–∞–ª–∞—à—Ç–æ–≤—É—é—á–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π"""
    llm = ChatOllama(
        model=model_name,  # –ù–∞–∑–≤–∞ –º–æ–¥–µ–ª—ñ –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
        temperature=MODEL_TEMPERATURE,  # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ 0 –¥–ª—è –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
        base_url=OLLAMA_URL,  # URL –¥–ª—è –≤–∑–∞—î–º–æ–¥—ñ—ó –∑ Ollama API
    )
    return llm



def rerank_search(documents, query, limit=10):
    """–ü–µ—Ä–µ—Ä–∞—Ö–æ–≤—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é BGE-reranker –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—ñ"""
    bge_rf = BGERerankFunction(
        model_name=RERANKER_MODEL,  # –ú–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–µ—Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è
        device="cuda" if torch.cuda.is_available() else "cpu",  # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CPU
        top_k=RERANK_K_RESULTS  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –Ω–∞–π–∫—Ä–∞—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–ª—è –ø–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è
    )
    reranked_results = bge_rf(query, documents)  # –ü–µ—Ä–µ—Ä–∞–Ω–∂—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    return reranked_results

def create_prompt(system_prompt):
    """–°—Ç–≤–æ—Ä—é—î —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç—É –¥–ª—è —á–∞—Ç-–º–æ–¥–µ–ª—ñ –∑ —Å–∏—Å—Ç–µ–º–Ω–∏–º –ø—Ä–æ–º–ø—Ç–æ–º —Ç–∞ –º—ñ—Å—Ü—è–º–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —ñ –ø–∏—Ç–∞–Ω–Ω—è"""
    return ChatPromptTemplate.from_messages([
        ("system",
         system_prompt),  # –°–∏—Å—Ç–µ–º–Ω–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø–æ–≤–µ–¥—ñ–Ω–∫–∏ –º–æ–¥–µ–ª—ñ
        ("human",
         "Context:\n{context}\n\nQuestion: {question}")  # –®–∞–±–ª–æ–Ω –¥–ª—è –∑–∞–ø–∏—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    ])


def create_stream_prompt(system_prompt, question, context):
    """–°—Ç–≤–æ—Ä—é—î —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç—É –¥–ª—è —á–∞—Ç-–º–æ–¥–µ–ª—ñ –∑ —Å–∏—Å—Ç–µ–º–Ω–∏–º –ø—Ä–æ–º–ø—Ç–æ–º —Ç–∞ –º—ñ—Å—Ü—è–º–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —ñ –ø–∏—Ç–∞–Ω–Ω—è"""
    prompt_text = (
    system_prompt +
    f"\n\nContext:\n{context}\n\nQuestion: {question}")
    return prompt_text



def create_chain(llm, prompt):
    """–°—Ç–≤–æ—Ä—é—î –ª–∞–Ω—Ü—é–∂–æ–∫ –æ–±—Ä–æ–±–∫–∏ –∑ LLM —Ç–∞ –ø—Ä–æ–º–ø—Ç—É –¥–ª—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏ –∑–∞–ø–∏—Ç—ñ–≤"""
    chain = prompt | llm  # –û–±'—î–¥–Ω–∞–Ω–Ω—è –ø—Ä–æ–º–ø—Ç—É —Ç–∞ –º–æ–¥–µ–ª—ñ –≤ –ª–∞–Ω—Ü—é–∂–æ–∫
    return chain

def get_llm_context(chain, context):
    """–û—Ç—Ä–∏–º—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ –º–æ–¥–µ–ª—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –Ω–∞–¥–∞–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–∏—Ç–∞–Ω–Ω—è"""
    response = chain.invoke(
        {
            "text": context,  # –ü–µ—Ä–µ–¥–∞—á–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤ –ª–∞–Ω—Ü—é–∂–æ–∫
        }
    )
    return response


def get_llm_response(chain, question, context):
    """–û—Ç—Ä–∏–º—É—î –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ –º–æ–¥–µ–ª—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–∏—Ç–∞–Ω–Ω—è —Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É"""
    response = chain.invoke(
    {
        "question": question,  # –ü–∏—Ç–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        "context": context,  # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
    })
    return response


def create_dir(dir_name):
    """–°—Ç–≤–æ—Ä—é—î –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –∑ –≤–∫–∞–∑–∞–Ω–æ—é –Ω–∞–∑–≤–æ—é, —è–∫—â–æ –≤–æ–Ω–∞ –Ω–µ —ñ—Å–Ω—É—î"""
    folder = Path(dir_name)  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –æ–±'—î–∫—Ç–∞ Path
    folder.mkdir(parents=True, exist_ok=True)  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –∑ –±–∞—Ç—å–∫—ñ–≤—Å—å–∫–∏–º–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è–º–∏

def create_logger(logger_name = __name__):
    """–°—Ç–≤–æ—Ä—é—î –ª–æ–≥–µ—Ä –∑ –≤–∫–∞–∑–∞–Ω–æ—é –Ω–∞–∑–≤–æ—é —Ç–∞ —Ä—ñ–≤–Ω–µ–º –ª–æ–≥—É–≤–∞–Ω–Ω—è INFO"""
    logger = logging.getLogger(logger_name)  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ª–æ–≥–µ—Ä–∞
    logger.setLevel(logging.INFO)  # –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è —Ä—ñ–≤–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
    return logger

def extract_video_id(url: str):
    """–í–∏—Ç—è–≥—É—î —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä –≤—ñ–¥–µ–æ –∑ URL YouTube –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤–∏—Ä–∞–∑—É"""
    youtube_regex = (
    r'(https?://)?(www\.)?'
    '(youtube|youtu|youtube-nocookie)\\.(com|be)/'
    '(watch\\?v=|embed/|v/|.+\\?v=)?([^&=%\\?]{11})')  # –†–µ–≥—É–ª—è—Ä–Ω–∏–π –≤–∏—Ä–∞–∑ –¥–ª—è –ø–æ—à—É–∫—É ID –≤—ñ–¥–µ–æ
    match = re.match(youtube_regex, url)  # –ü–æ—à—É–∫ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
    if match:
        return match.group(6)  # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è ID –≤—ñ–¥–µ–æ
    return ""  # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è –ø–æ—Ä–æ–∂–Ω—å–æ–≥–æ —Ä—è–¥–∫–∞, —è–∫—â–æ ID –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ

def clean_filename(filename: str) -> str:
    """–û—á–∏—â–µ–Ω–Ω—è —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É –≤—ñ–¥ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤ –¥–ª—è –±–µ–∑–ø–µ—á–Ω–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è"""
    # –í–∏–¥–∞–ª—è—î–º–æ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ñ —Å–∏–º–≤–æ–ª–∏ –¥–ª—è —ñ–º–µ–Ω —Ñ–∞–π–ª—ñ–≤
    return re.sub(r'[\\/*?:"<>|]', "", filename)  # –ó–∞–º—ñ–Ω–∞ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤ –Ω–∞ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫

def query_ollama(prompt, model, image_b64=None):
    return ollama.chat(
        model=model,
        messages=[{"role":"user","content":prompt,"images": image_b64}],
        stream=True               # <- returns a generator
    )

def image_to_base64(image):
    """–ö–æ–Ω–≤–µ—Ä—Ç—É—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —É —Ñ–æ—Ä–º–∞—Ç base64 –¥–ª—è –ø–µ—Ä–µ–¥–∞—á—ñ –≤ API"""
    if image.mode == "RGBA":
        image = image.convert("RGB")  # –ü—Ä–∏–±–∏—Ä–∞—î–º–æ –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª –¥–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ
    img_byte_arr = io.BytesIO()  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –±—É—Ñ–µ—Ä–∞ –¥–ª—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    image.save(img_byte_arr, format="JPEG")  # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —É —Ñ–æ—Ä–º–∞—Ç—ñ JPEG
    return base64.b64encode(img_byte_arr.getvalue()).decode("utf-8")  # –ö–æ–¥—É–≤–∞–Ω–Ω—è –≤ base64


def process_video(url: str, video_dir: str, model_size: str):
    """–û–±—Ä–æ–±–ª—è—î –≤—ñ–¥–µ–æ –∑ YouTube: –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î, —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±—É—î —Ç–∞ —Ä–æ–∑–±–∏–≤–∞—î –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏ –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É"""
    whisper_model = get_whisper(model_size)  # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ Whisper (–∫–µ—à—É—î—Ç—å—Å—è)
    logger = logging.getLogger(__name__)  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ª–æ–≥–µ—Ä–∞
    
    video_chunks = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è —á–∞—Å—Ç–∏–Ω –≤—ñ–¥–µ–æ
    video_id = extract_video_id(url)  # –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è ID –≤—ñ–¥–µ–æ
    unique_video_id = f"{video_id}_{hashlib.md5(url.encode()).hexdigest()[:8]}"  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ ID
    if not video_id:
        raise ValueError("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–π URL –≤—ñ–¥–µ–æ YouTube")  # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ—Ä–µ–∫—Ç–Ω–æ—Å—Ç—ñ URL
    st.markdown(f"–û–±—Ä–æ–±–∫–∞ –≤—ñ–¥–µ–æ –∑ URL: {url}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø–æ—á–∞—Ç–∫—É –æ–±—Ä–æ–±–∫–∏
    try:
        # –°—Ç–≤–æ—Ä—é—î–º–æ –æ–±'—î–∫—Ç Path –¥–ª—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
        video_dir_path = Path(video_dir)  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –æ–±'—î–∫—Ç–∞ Path
        video_dir_path.mkdir(parents=True, exist_ok=True)  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó

        with yt_dlp.YoutubeDL({'quiet': True}) as ydl:
            logger.info("–û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –≤—ñ–¥–µ–æ...")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
            info = ydl.extract_info(url, download=False)  # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –≤—ñ–¥–µ–æ
            # –û—Ç—Ä–∏–º—É—î–º–æ —Ç–∞ –æ—á–∏—â—É—î–º–æ –Ω–∞–∑–≤—É
            if st.session_state.video_name:
                title = st.session_state.video_name
            else:
                title = info.get("alt_title", "video")  # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –Ω–∞–∑–≤–∏ –≤—ñ–¥–µ–æ
            st.markdown(f"–ù–∞–∑–≤–∞ –≤—ñ–¥–µ–æ: {title}")
            safe_title = clean_filename(title)  # –û—á–∏—â–µ–Ω–Ω—è –Ω–∞–∑–≤–∏
            unique_safe_title = f"{safe_title}_{hashlib.md5(url.encode()).hexdigest()[:8]}"  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ—ó –Ω–∞–∑–≤–∏
            logger.info(f"–û—Ç—Ä–∏–º–∞–Ω–æ –Ω–∞–∑–≤—É –≤—ñ–¥–µ–æ: {title}, –æ—á–∏—â–µ–Ω–∞ –Ω–∞–∑–≤–∞: {safe_title}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è

            video_info = {
                    "title": title,  # –ù–∞–∑–≤–∞ –≤—ñ–¥–µ–æ
                    "uploader": info.get("uploader", "–ù–µ–≤—ñ–¥–æ–º–∏–π –∞–≤—Ç–æ—Ä"),  # –ê–≤—Ç–æ—Ä –≤—ñ–¥–µ–æ
                    "duration": info.get("duration", 0),  # –¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –≤—ñ–¥–µ–æ
                    "upload_date": info.get("upload_date", ""),  # –î–∞—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
                    "view_count": info.get("view_count", 0),  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–≥–ª—è–¥—ñ–≤
                    "like_count": info.get("like_count", 0),  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ª–∞–π–∫—ñ–≤
                    "description": info.get("description", ""),  # –û–ø–∏—Å –≤—ñ–¥–µ–æ
                    "video_id": video_id}  # ID –≤—ñ–¥–µ–æ
            logger.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ –≤—ñ–¥–µ–æ: {video_info['title']} ({video_info['duration']} —Å–µ–∫)")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è

            file_path = video_dir_path / f"{safe_title}.mp4"  # –®–ª—è—Ö –¥–æ –≤—ñ–¥–µ–æ
            final_audio_path = video_dir_path / f"{safe_title}.mp3"  # –®–ª—è—Ö –¥–æ –∞—É–¥—ñ–æ
            transcript_path = video_dir_path / f"{safe_title}_transcript.txt"  # –®–ª—è—Ö –¥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó
            
            logger.info(f"–®–ª—è—Ö–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤:")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
            logger.info(f"–í—ñ–¥–µ–æ: {file_path}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
            logger.info(f"–ê—É–¥—ñ–æ: {final_audio_path}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è: {transcript_path}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è

            ydl_opts = {
                'format': 'bestvideo[height<=720]+bestaudio/best[height<=720]',  # –§–æ—Ä–º–∞—Ç –≤—ñ–¥–µ–æ
                'paths': {'home': str(video_dir_path)},  # –®–ª—è—Ö –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
                'outtmpl': {'default': f'{safe_title}.%(ext)s'},  # –®–∞–±–ª–æ–Ω —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É
                'postprocessors': [
                    {'key': 'FFmpegVideoConvertor', 'preferedformat': 'mp4'},  # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —É mp4
                    {'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}  # –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ
                ],
                'merge_output_format': 'mp4',  # –§–æ—Ä–º–∞—Ç –≤–∏—Ö–æ–¥—É
                'keepvideo': True,  # –ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –≤—ñ–¥–µ–æ
                'quiet': True,  # –¢–∏—Ö–∏–π —Ä–µ–∂–∏–º
                'noplaylist': True  # –ë–µ–∑ –ø–ª–µ–π–ª–∏—Å—Ç—ñ–≤
            }

            with yt_dlp.YoutubeDL(ydl_opts) as ydl_download:
                if not file_path.exists() or not final_audio_path.exists():
                    logger.info("–ü–æ—á–∏–Ω–∞—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—ñ–¥–µ–æ...")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
                    ydl_download.download([url])  # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—ñ–¥–µ–æ
                    logger.info("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
                else:
                    logger.info("–§–∞–π–ª–∏ –≤–∂–µ —ñ—Å–Ω—É—é—Ç—å, –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è

            if not file_path.exists():
                logger.error(f"–í—ñ–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—ñ—Å–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {file_path}")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø–æ–º–∏–ª–∫–∏
                raise FileNotFoundError(f"–í—ñ–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {file_path}")  # –í–∏–∫–ª–∏–∫ –ø–æ–º–∏–ª–∫–∏

            logger.info("–ü–æ—á–∏–Ω–∞—î–º–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü—ñ—é...")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
            result = whisper_model.transcribe(str(file_path))
            placeholder = st.empty()
              # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü—ñ—è –≤—ñ–¥–µ–æ
            transcript = result["text"]
            placeholder.text(transcript)   # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –æ—Ç—Ä–∏–º–∞–Ω–æ {len(transcript)} —Å–∏–º–≤–æ–ª—ñ–≤")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è
            
            with open(transcript_path, 'w', encoding='utf-8') as f:
                f.write(transcript)  # –ó–∞–ø–∏—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó —É —Ñ–∞–π–ª
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—é –∑–±–µ—Ä–µ–∂–µ–Ω–æ")  # –õ–æ–≥—É–≤–∞–Ω–Ω—è

            return  transcript, file_path, title, unique_video_id
    

    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –≤—ñ–¥–µ–æ: {str(e)}", exc_info=True)  # –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø–æ–º–∏–ª–∫–∏
        raise


def build_video_json(
    txt: str,
    meta: Dict[str, Any],
    file_path: str,
    original_filename: str,
    chunk_size: int = st.session_state.chunk_size,
    overlap: int = st.session_state.chunk_overlap,
) -> Dict[str, Any]:
    """
    –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î —Ä–æ–∑—à–∏—Ñ—Ä–æ–≤–∫—É –≤—ñ–¥–µ–æ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –≤ Milvus,
    –≤–∫–ª—é—á–∞—é—á–∏ –º–µ—Ç–∞–¥–∞–Ω—ñ –≤—ñ–¥–µ–æ —Ç–∞ —Ä–æ–∑–±–∏—Ç—Ç—è —Ç–µ–∫—Å—Ç—É –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
    """
    file_path = str(file_path)  # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —à–ª—è—Ö—É –Ω–∞ —Ä—è–¥–æ–∫
    original_uuid = hashlib.sha256(txt.encode()).hexdigest()  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ ID
    doc_id = f"vid_{meta['video_id']}"  # –î–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏–π ID
    chunks = chunk_text(txt, size=chunk_size, overlap=overlap)  # –†–æ–∑–±–∏—Ç—Ç—è —Ç–µ–∫—Å—Ç—É –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
    upload_date = dt.now().isoformat()  # –ü–æ—Ç–æ—á–Ω–∞ –¥–∞—Ç–∞ —Ç–∞ —á–∞—Å

    return {
        "doc_id": doc_id,
        "original_uuid": original_uuid,
        "title": meta.get("title", ""),
        "video_meta": {                               # –≤—Å—ñ –º–µ—Ç–∞–¥–∞–Ω—ñ –≤—ñ–¥–µ–æ
            "video_id":     meta["video_id"],
            "title":        meta.get("title", ""),
            
        },
        "content": txt,
        "chunks": [
            {
                "chunk_id":       f"{doc_id}_chunk_{i}",
                "original_index": i,
                "content":        c,
                "file_path":      file_path,
                "file_name":      original_filename,
                "upload_date":    upload_date,
            }
            for i, c in enumerate(chunks)
        ],
    }




def extract_audio_from_video(video_path: str) -> bytes:
    """
    Run FFmpeg to decode the audio track to 16 kHz, mono, 16-bit PCM,
    then convert to float32 in [-1.0, +1.0] for Whisper.
    """
    cmd = [
        "ffmpeg", "-nostdin", "-y",
        "-i", video_path,
        "-f", "s16le", "-ac", "1", "-acodec", "pcm_s16le", "-ar", "16000",
        "pipe:1"
    ]
    # Capture stdout, suppress stderr noise
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
    pcm_bytes, _ = proc.communicate()
    if proc.returncode != 0:
        raise RuntimeError(f"FFmpeg exited with code {proc.returncode}")

    # Interpret bytes as int16 little-endian, then scale to float32
    audio_int16 = np.frombuffer(pcm_bytes, dtype=np.int16)
    audio_float = audio_int16.astype(np.float32) / 32768.0
    return audio_float

# –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –µ–∫—Å—Ç—Ä–∞–∫—Ü—ñ—ó –¥–∞–Ω–∏—Ö –∑ —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ —Ñ–∞–π–ª—ñ–≤
def data_extraction(path):
    """–í–∏–∑–Ω–∞—á–∞—î —Ç–∏–ø —Ñ–∞–π–ª—É –∑–∞ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è–º —Ç–∞ –≤–∏–∫–ª–∏–∫–∞—î –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—É —Ñ—É–Ω–∫—Ü—ñ—é –µ–∫—Å—Ç—Ä–∞–∫—Ü—ñ—ó"""
    ext = path.rsplit(".", 1)[-1].lower()  # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è —Ñ–∞–π–ª—É
    if ext == "pdf":
        return extract_from_pdf(path)  # –ï–∫—Å—Ç—Ä–∞–∫—Ü—ñ—è –∑ PDF
    if ext in ("xlsx", "xls"):
        return extract_from_excel(path)  # –ï–∫—Å—Ç—Ä–∞–∫—Ü—ñ—è –∑ Excel
    if ext in ("doc", "docx"):
        return extract_from_word(path)  # –ï–∫—Å—Ç—Ä–∞–∫—Ü—ñ—è –∑ Word
    if ext == "md":
        return extract_from_markdown(path)  # –ï–∫—Å—Ç—Ä–∞–∫—Ü—ñ—è –∑ Markdown
    if ext == "csv":
        return extract_from_csv(path)  # –ï–∫—Å—Ç—Ä–∞–∫—Ü—ñ—è –∑ CSV
    raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {ext}")  # –í–∏–∫–ª–∏–∫ –ø–æ–º–∏–ª–∫–∏ –¥–ª—è –Ω–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤

def extract_from_pdf(p):
    """–í–∏—Ç—è–≥—É—î —Ç–µ–∫—Å—Ç –∑ PDF-—Ñ–∞–π–ª—É, –æ–±'—î–¥–Ω—É—é—á–∏ —Ç–µ–∫—Å—Ç –∑ —É—Å—ñ—Ö —Å—Ç–æ—Ä—ñ–Ω–æ–∫"""
    txt = ""  # –ü–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
    with open(p, "rb") as f:
        for pg in PdfReader(f).pages:  # –ü–µ—Ä–µ–±—ñ—Ä —Å—Ç–æ—Ä—ñ–Ω–æ–∫
            txt += pg.extract_text() or ""  # –î–æ–¥–∞–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É —Å—Ç–æ—Ä—ñ–Ω–∫–∏
    return txt  # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É

def extract_from_excel(p, **kw):
    """–í–∏—Ç—è–≥—É—î –¥–∞–Ω—ñ –∑ Excel-—Ñ–∞–π–ª—É, –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—é—á–∏ —ó—Ö –Ω–∞ DataFrame"""
    return pd.read_excel(p, dtype=str, **kw).fillna("")  # –ß–∏—Ç–∞–Ω–Ω—è Excel-—Ñ–∞–π–ª—É —Ç–∞ –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –ø—Ä–æ–ø—É—Å–∫—ñ–≤

def extract_from_word(p):
    """–í–∏—Ç—è–≥—É—î —Ç–µ–∫—Å—Ç –∑ Word-–¥–æ–∫—É–º–µ–Ω—Ç–∞, –æ–±'—î–¥–Ω—É—é—á–∏ —Ç–µ–∫—Å—Ç –∑ —É—Å—ñ—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ñ–≤"""
    return "\n".join(par.text for par in DocxDocument(p).paragraphs)  # –û–±'—î–¥–Ω–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ñ–≤

def extract_from_markdown(p):
    """–í–∏—Ç—è–≥—É—î —Ç–µ–∫—Å—Ç –∑ Markdown-—Ñ–∞–π–ª—É, —á–∏—Ç–∞—é—á–∏ –π–æ–≥–æ —è–∫ —Ç–µ–∫—Å—Ç–æ–≤–∏–π —Ñ–∞–π–ª"""
    return open(p, encoding="utf-8").read()  # –ß–∏—Ç–∞–Ω–Ω—è —Ñ–∞–π–ª—É

def extract_from_csv(p, **kw):
    """–í–∏—Ç—è–≥—É—î –¥–∞–Ω—ñ –∑ CSV-—Ñ–∞–π–ª—É, –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—é—á–∏ —ó—Ö –Ω–∞ DataFrame"""
    return pd.read_csv(p, dtype=str, **kw).fillna("")  # –ß–∏—Ç–∞–Ω–Ω—è CSV-—Ñ–∞–π–ª—É —Ç–∞ –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –ø—Ä–æ–ø—É—Å–∫—ñ–≤

def prepare_text(text: Any) -> str:
    """
    –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç—É (DataFrame, dict, –∞–±–æ —ñ–Ω—à–∏–π —Ç–∏–ø) –¥–æ –æ–±—Ä–æ–±–∫–∏, –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—é—á–∏ –π–æ–≥–æ –Ω–∞ —á–∏—Å—Ç–∏–π —Ä—è–¥–æ–∫
    """
    # 1) –Ø–∫—â–æ DataFrame ‚Äî —Å–∫–ª–µ—é—î–º–æ –≤—Å—ñ –∫–æ–º—ñ—Ä–∫–∏
    if isinstance(text, pd.DataFrame):
        # –æ–±'—î–¥–Ω—É—î–º–æ –≤—Å—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –æ–¥–∏–Ω —Ä—è–¥–æ–∫
        text = ' '.join(text.values.flatten().astype(str))  # –û–±'—î–¥–Ω–∞–Ω–Ω—è –≤—Å—ñ—Ö –∑–Ω–∞—á–µ–Ω—å
    # 2) –Ø–∫—â–æ dict ‚Äî —Å–∫–ª–µ—é—î–º–æ –≤—Å—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    elif isinstance(text, dict):
        text = ' '.join(str(v) for v in text.values())  # –û–±'—î–¥–Ω–∞–Ω–Ω—è –≤—Å—ñ—Ö –∑–Ω–∞—á–µ–Ω—å
    # 3) –Ø–∫—â–æ –Ω–µ —Ä—è–¥–æ–∫ ‚Äî –ø—Ä–∏–≤–æ–¥–∏–º–æ –¥–æ —Ä—è–¥–∫–∞
    elif not isinstance(text, str):
        text = str(text)  # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–∞ —Ä—è–¥–æ–∫

    # 4) –û—á–∏—â–∞—î–º–æ –æ—Ç—Ä–∏–º–∞–Ω–∏–π —Ä—è–¥–æ–∫
    # –≤–∏–¥–∞–ª—è—î–º–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤, —Ç–∞–±—É–ª—è—Ü—ñ—ó —Ç–∞ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏
    txt = text.replace('\r', ' ').replace('\n', ' ').replace('\t', ' ')  # –ó–∞–º—ñ–Ω–∞ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤
    txt = ' '.join(txt.split())  # –ø—Ä–∏–±–∏—Ä–∞—î–º–æ –ø–æ–¥–≤—ñ–π–Ω—ñ/–∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏

    return txt.strip()  # –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è –æ—á–∏—â–µ–Ω–æ–≥–æ —Ä—è–¥–∫–∞

def chunk_text(text: str, size=st.session_state.chunk_size, overlap=st.session_state.chunk_overlap):
    """–†–æ–∑–±–∏–≤–∞—î —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏ –≤–∫–∞–∑–∞–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É –∑ –ø–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è–º –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –ø–æ—à—É–∫—É"""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=size,  # –†–æ–∑–º—ñ—Ä —á–∞—Å—Ç–∏–Ω–∏
        chunk_overlap=overlap,  # –ü–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è –º—ñ–∂ —á–∞—Å—Ç–∏–Ω–∞–º–∏
        length_function=len,  # –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –¥–æ–≤–∂–∏–Ω–∏
        is_separator_regex=False  # –ë–µ–∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ä–µ–≥—É–ª—è—Ä–Ω–∏—Ö –≤–∏—Ä–∞–∑—ñ–≤
    )
    return splitter.split_text(text)  # –†–æ–∑–±–∏—Ç—Ç—è —Ç–µ–∫—Å—Ç—É


def build_json(text: str, original_filename: str, path: str) -> dict:
    """–°—Ç–≤–æ—Ä—é—î JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —Ç–µ–∫—Å—Ç—É –∑ –º–µ—Ç–∞–¥–∞–Ω–∏–º–∏ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –≤ Milvus"""
    original_uuid = hashlib.sha256(text.encode()).hexdigest()  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ ID
    doc_id = original_uuid[:16]  # –§—ñ–∫—Å–æ–≤–∞–Ω–∏–π —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä (–ø–µ—Ä—à—ñ 16 —Å–∏–º–≤–æ–ª—ñ–≤)
    chunks = chunk_text(text)  # –†–æ–∑–±–∏—Ç—Ç—è —Ç–µ–∫—Å—Ç—É –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
    upload_date = dt.now().isoformat()  # –ü–æ—Ç–æ—á–Ω–∞ –¥–∞—Ç–∞ —Ç–∞ —á–∞—Å
    return {
        "doc_id": doc_id,  # ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
        "original_uuid": original_uuid,  # –ü–æ–≤–Ω–∏–π —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID
        "content": text,  # –ü–æ–≤–Ω–∏–π —Ç–µ–∫—Å—Ç
        "chunks": [
            {
                "chunk_id": f"{doc_id}_c{i}",  # ID —á–∞—Å—Ç–∏–Ω–∏ (–¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏–π)
                "original_index": i,  # –Ü–Ω–¥–µ–∫—Å —á–∞—Å—Ç–∏–Ω–∏
                "content": c,  # –¢–µ–∫—Å—Ç —á–∞—Å—Ç–∏–Ω–∏
                "file_path": path,  # –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É
                "file_name": original_filename,  # –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ –Ω–∞–∑–≤–∞ —Ñ–∞–π–ª—É
                "upload_date": upload_date,  # –î–∞—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
            }
            for i, c in enumerate(chunks)  # –ü–µ—Ä–µ–±—ñ—Ä —á–∞—Å—Ç–∏–Ω
        ],
    }


def build_image_json(text: str, file_path: str, original_filename: str) -> dict:
    """–°—Ç–≤–æ—Ä—é—î JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –æ–ø–∏—Å–æ–º —Ç–∞ –º–µ—Ç–∞–¥–∞–Ω–∏–º–∏ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –≤ Milvus"""
    txt = prepare_text(text)  # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç—É

    original_uuid = hashlib.sha256(txt.encode()).hexdigest()  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ ID
    doc_id = original_uuid[:16]  # –§—ñ–∫—Å–æ–≤–∞–Ω–∏–π —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä (–ø–µ—Ä—à—ñ 16 —Å–∏–º–≤–æ–ª—ñ–≤)
    chunks = chunk_text(txt)  # –†–æ–∑–±–∏—Ç—Ç—è —Ç–µ–∫—Å—Ç—É –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
    upload_date = dt.now().isoformat()  # –ü–æ—Ç–æ—á–Ω–∞ –¥–∞—Ç–∞ —Ç–∞ —á–∞—Å

    return {
        "doc_id": doc_id,  # ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
        "original_uuid": original_uuid,  # –ü–æ–≤–Ω–∏–π —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID
        "content": txt,  # –ü–æ–≤–Ω–∏–π —Ç–µ–∫—Å—Ç
        "chunks": [
            {
                "chunk_id": f"{doc_id}_c{i}",  # ID —á–∞—Å—Ç–∏–Ω–∏ (–¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏–π)
                "content": c,  # –¢–µ–∫—Å—Ç —á–∞—Å—Ç–∏–Ω–∏
                "file_path": file_path,  # –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É
                "file_name": original_filename,  # –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ –Ω–∞–∑–≤–∞ —Ñ–∞–π–ª—É
                "upload_date": upload_date,  # –î–∞—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
                "original_index": i,  # –Ü–Ω–¥–µ–∫—Å —á–∞—Å—Ç–∏–Ω–∏
            }
            for i, c in enumerate(chunks)  # –ü–µ—Ä–µ–±—ñ—Ä —á–∞—Å—Ç–∏–Ω
        ],
    }


def init_db():
    """
    –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î –±–∞–∑—É –¥–∞–Ω–∏—Ö, —Å—Ç–≤–æ—Ä—é—é—á–∏ —Ç–∞–±–ª–∏—Ü—é history, —è–∫—â–æ –≤–æ–Ω–∞ –Ω–µ —ñ—Å–Ω—É—î.
    –¢–∞–±–ª–∏—Ü—è –º—ñ—Å—Ç–∏—Ç—å –ø–æ–ª—è:
    - id: —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä –∑–∞–ø–∏—Å—É
    - ts: —á–∞—Å–æ–≤–∞ –º—ñ—Ç–∫–∞ –≤–∑–∞—î–º–æ–¥—ñ—ó
    - mode: —Ä–µ–∂–∏–º –≤–∑–∞—î–º–æ–¥—ñ—ó (–¥–æ–∫—É–º–µ–Ω—Ç, –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, –≤—ñ–¥–µ–æ, —á–∞—Ç)
    - query: –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    - answer: –≤—ñ–¥–ø–æ–≤—ñ–¥—å —Å–∏—Å—Ç–µ–º–∏
    """
    conn = sqlite3.connect(DB_PATH)  # –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
    cur = conn.cursor()  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫—É—Ä—Å–æ—Ä–∞ –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è SQL-–∑–∞–ø–∏—Ç—ñ–≤
    cur.execute(
        """CREATE TABLE IF NOT EXISTS history(
                id     INTEGER PRIMARY KEY AUTOINCREMENT,  
                ts     TEXT,  
                mode   TEXT,  
                query  TEXT,  
                answer TEXT   
        )"""
    )
    conn.commit(); conn.close()  # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–º—ñ–Ω —Ç–∞ –∑–∞–∫—Ä–∏—Ç—Ç—è –∑'—î–¥–Ω–∞–Ω–Ω—è

def get_conn():
    """–°—Ç–≤–æ—Ä—é—î –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ –±–∞–∑–æ—é –¥–∞–Ω–∏—Ö —Ç–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î —Ç–∞–±–ª–∏—Ü—é, —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ"""
    conn = sqlite3.connect(DB_PATH)
    # —Å—Ç–≤–æ—Ä—é—î–º–æ —Ç–∞–±–ª–∏—Ü—é –æ–¥–∏–Ω —Ä–∞–∑
    conn.execute(
        """CREATE TABLE IF NOT EXISTS history (
               id     INTEGER PRIMARY KEY AUTOINCREMENT,
               ts     TEXT,
               mode   TEXT,
               query  TEXT,
               answer TEXT
           )"""
    )
    return conn

def log_interaction(mode, query, answer):
    """–ó–∞–ø–∏—Å—É—î –≤–∑–∞—î–º–æ–¥—ñ—é –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑ —Å–∏—Å—Ç–µ–º–æ—é –≤ –±–∞–∑—É –¥–∞–Ω–∏—Ö"""
    ts = datetime.now().isoformat(timespec="seconds")
    with get_conn() as conn:
        conn.execute(
            "INSERT INTO history(ts,mode,query,answer) VALUES (?,?,?,?)",
            (ts, mode, query, answer),
        )
@st.cache_resource(show_spinner="–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å Whisper‚Ä¶")
def get_whisper(model_size: str = "base"):
    return whisper.load_model(model_size, device="cuda" if torch.cuda.is_available() else "cpu")

def build_audio_json(
    txt: str,
    meta: Dict[str, Any],
    file_path: str,
    original_filename: str,
    chunk_size: int = st.session_state.chunk_size,
    overlap: int = st.session_state.chunk_overlap,
) -> Dict[str, Any]:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –µ–¥–∏–Ω—ã–π JSON –¥–ª—è –∞—É–¥–∏–æ:
    - —Ä–∞–∑–±–∏–≤–∞–µ—Ç prepared-text –Ω–∞ —á–∞–Ω–∫–∏
    - —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –≥–æ—Ç–æ–≤—É—é –∫ upsert –≤ Milvus
    """
    file_path = str(file_path)
    original_uuid = hashlib.sha256(txt.encode()).hexdigest()
    doc_id = f"aud_{meta['unique_audio_id']}"
    chunks = chunk_text(txt, size=chunk_size, overlap=overlap)

    return {
        "doc_id": doc_id,
        "original_uuid": original_uuid,
        "audio_meta": {
            "audio_id":         meta["audio_id"],
            "unique_audio_id":  meta["unique_audio_id"],
            "title":            meta["title"],
            "upload_date":      meta["upload_date"],
        },
        "content": txt,
        "chunks": [
            {
                "chunk_id":       f"{doc_id}_chunk_{i}",
                "original_index": i,
                "content":        c,
                "file_path":      file_path,
                "file_name":      original_filename,
                "upload_date":    meta["upload_date"],
            }
            for i, c in enumerate(chunks)
        ],
    }


def process_audio(filepath: str, model_size: str, dir_name: str, title: str) -> str:
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É—î –∞—É–¥—ñ–æ —ñ –ø–æ–≤–µ—Ä—Ç–∞—î —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç.
    –ù–∏—á–µ–≥–æ –±–æ–ª—å—à–µ –Ω–µ –¥–µ–ª–∞–µ—Ç ‚Äî –Ω–µ —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —á–∞–Ω–∫–∏ –∏ –Ω–µ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.
    """
    # –ó–∞–≥—Ä—É–∑–∏–ª–∏ –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ (–∫–µ—à–∏—Ä—É–µ—Ç—Å—è get_whisper)
    whisper_model = get_whisper(model_size)
    logger = logging.getLogger(__name__)
    logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü—ñ—è –∞—É–¥—ñ–æ: {filepath}")

# --- –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü—ñ—è –∞—É–¥—ñ–æ ---
#–î–ª—è —Ç–æ–≥–æ –∞–±–∏ –∑–º—É—Å–∏—Ç–∏ –º–æ–¥–µ–ª—å –ø–æ–≤–µ—Ä—Ç–∞—Ç–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç, –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ —Ç–∞–º –Ω–∞ –ø–æ—á–∞—Ç–∫—É —î –º—É–∑—ñ–∫–∞, –ø–æ—Ç—Ä—ñ–±–Ω–æ —â–æ–± –∑ –ø–æ—á–∞—Ç–∫—É —Ñ–∞–π–ª—É –±—É–≤ –≥–æ–ª–æ—Å –∞ –Ω–µ –º—É–∑–∏–∫–∞ —Ç–∞ —â–æ–± —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É —å—É–≤ —è–∫—ñ—Å–Ω–∏–π (wav):
    result = whisper_model.transcribe(str(filepath))
    placeholder = st.empty()
    transcript = result["text"]
    placeholder.text(transcript) 
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Ä—è–¥–æ–º —Å —Ñ–∞–π–ª–æ–º
    transcript_path = os.path.join(dir_name, f"{title}_transcript.txt")
    with open(transcript_path, "w", encoding="utf-8") as f:
        f.write(transcript)
    logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {transcript_path}")
    return transcript


def audio_mode(collection_name: str, summary: bool):
    audio_dir = "audio"
    create_dir(audio_dir)

    uploaded_file = st.file_uploader(
        "–û–±–µ—Ä—ñ—Ç—å –∞—É–¥—ñ–æ—Ñ–∞–π–ª",
        type=["mp3", "wav", "flac", "aac", "m4a", "ogg"],
    )
    if uploaded_file is None:
        return

    # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ ---
    full_name = uploaded_file.name
    title, ext = os.path.splitext(full_name)
    filepath = os.path.join(audio_dir, full_name)
    with open(filepath, "wb") as f:
        f.write(uploaded_file.getbuffer())

    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    audio_id         = Path(filepath).stem
    safe_title       = clean_filename(title)
    unique_audio_id = f"{audio_id}_{hashlib.md5(filepath.encode()).hexdigest()[:8]}"
    upload_date      = dt.now().isoformat()

    meta = {
        "title":             title,
        "audio_id":          audio_id,
        "unique_audio_id":   unique_audio_id,
        "upload_date":       upload_date,
    }

    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ –∫–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞
    model_size = st.selectbox(
        "–ú–æ–¥–µ–ª—å Whisper:",
        ["tiny", "base", "small", "medium", "large"],
        index=1,
    )
    if not st.button("–û–±—Ä–æ–±–∏—Ç–∏"):
        return

    # --- –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è ---
    transcript = process_audio(filepath, model_size, audio_dir, title)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∫ —á–∞–Ω–∫–∏–Ω–≥—É
    cleaned = prepare_text(transcript)
    st.session_state.audio_context_text['context'] = ""
    if summary and not st.session_state.audio_context_text.get("context"):
        llm = create_llm("qwen3:14b")
        summary = summarise_transcript(cleaned, llm)
        st.session_state.audio_context_text["context"] = summary

    # --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –µ–¥–∏–Ω–æ–≥–æ JSON ---
    audio_json = build_audio_json(
        txt=cleaned,
        meta=meta,
        file_path=filepath,
        original_filename=full_name,
    )
    st.session_state["last_audio_json"] = audio_json
    st.session_state.audio_processed = True

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Milvus ---
    dense_ef = create_bge_m3_embeddings()
    retriever = AudioHybridRetriever(
        client=st.session_state.milvus_client,
        collection_name=collection_name,
        dense_embedding_function=dense_ef,
    )
    if st.session_state.audio_processed:
        retriever.build_collection()
        for chunk in audio_json["chunks"]:
            metadata = {
                **audio_json["audio_meta"],
                "doc_id":        audio_json["doc_id"],
                "original_uuid": audio_json["original_uuid"],
                "chunk_id":      chunk["chunk_id"],
                "original_index": chunk["original_index"],
                "file_path":      chunk["file_path"],
                "file_name":      chunk["file_name"],
                "upload_date":    chunk["upload_date"],
            }
            retriever.upsert_data(chunk["content"], metadata)

    st.success("–ê—É–¥—ñ–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –≤ –∫–æ–ª–µ–∫—Ü—ñ—é.")
    st.session_state.audio_processed = True


def chat_audio_mode(collection_name, llm_option):
    if st.session_state.audio_context_text['context']:
        st.markdown(st.session_state.audio_context_text['context'])
    if not st.session_state.messages:
        st.session_state.messages.append({"role": "assistant", "content": "–ü—Ä–∏–≤—ñ—Ç! –Ø –≥–æ—Ç–æ–≤–∏–π –¥–æ —Ä–æ–∑–º–æ–≤–∏. –©–æ –≤–∞—Å —Ü—ñ–∫–∞–≤–∏—Ç—å?"})
         
    for m in st.session_state.messages:
        with st.chat_message(m["role"]): st.markdown(m["content"])
    placeholder = st.empty()

    # –≤–≤–æ–¥ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    if q := st.chat_input("–í–∞—à –∑–∞–ø–∏—Ç"):
        st.session_state.messages.append(dict(role="user", content=q))
        with st.chat_message("user"): st.markdown(q)
        with st.chat_message("assistant"):
            st.write("–®—É–∫–∞—é –≤—ñ–¥–ø–æ–≤—ñ–¥—å‚Ä¶")
            dense_ef = create_bge_m3_embeddings()
            retr = AudioHybridRetriever(
            client=st.session_state.milvus_client,
            collection_name=collection_name,
            dense_embedding_function=dense_ef,) 
            retr.build_collection()
            chunks = retr.search(q, mode="hybrid", k=st.session_state.ret_k_results)
            ctx = "\n---\n".join([c["content"] for c in chunks]) if chunks else ""
            user_query = q+"\n---\n"+ctx
            if llm_option == "–£–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω—É":
                    # –§–æ—Ä–º—É—î–º–æ —î–¥–∏–Ω–∏–π —Ä—è–¥–æ–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
                    system = UKR_SYSTEM_PROMPT
                    prompt_text = system + "\n\n" + user_query
                    # –í–∏–∫–ª–∏–∫–∞—î–º–æ HuggingFace pipeline, —è–∫–∏–π –æ—á—ñ–∫—É—î —Ä—è–¥–æ–∫
                    gen = st.session_state.ukr_generator(
                            [
                                {"role": "user", "content": user_query}
                            ],
                            max_new_tokens=MAX_TOKENS,
                            do_sample=False)
                    # –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —Å–ø–∏—Å–æ–∫ –∑ –æ–¥–Ω–∏–º —Å–ª–æ–≤–Ω–∏–∫–æ–º —ñ–∑ –∫–ª—é—á–µ–º "generated_text"
                    answer = gen[0]["generated_text"]
            else:   
                placeholder = st.empty()
                answer = ""
                prompt = create_stream_prompt(st.session_state.system_prompt, q, ctx)
                model = st.session_state.llm_option
                for part in query_ollama(prompt, model):
                    chunk = part["message"]["content"]
                    # –ø–æ‚Äë—Å–∏–º–≤–æ–ª—å–Ω–æ –¥–æ–¥–∞—î–º–æ —Ç–∞ –æ–¥—Ä–∞–∑—É –æ–Ω–æ–≤–ª—é—î–º–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                    for ch in chunk:
                        answer += ch
                        placeholder.text(answer)   # –∞–±–æ .markdown(caption)

            with st.expander("–ü–æ–∫–∞–∑–∞—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"):
                for i in chunks:
                        st.markdown(
                            f"**–§–∞–π–ª:** {i['file_name']}  \n"
                            f"**Chunk ID:** `{i['chunk_id']}`  \n"
                            f"**–î–∞—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è:** {i['upload_date']}  \n"
                            f"**Score:** {i['score']:.4f}  \n\n"
                            f"> {i['content']}",
                        )
            log_interaction(st.session_state.current_mode, q, answer)
            st.session_state.messages.append(dict(role="assistant", content=answer))

def video_mode(collection_name: str, summary: bool):
    st.session_state.current_mode = "video"
    st.subheader("–û–±—Ä–æ–±–∫–∞ –≤—ñ–¥–µ–æ")
    col1, col2 = st.columns(2)
    with col1:
        url = st.text_input("–í–≤–µ–¥—ñ—Ç—å –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –≤—ñ–¥–µ–æ –≤ YouTube", key="video_url")
    with col2:
        uploaded_video = st.file_uploader(
            "Upload local video", type=["mp4","mov","avi","mpeg"],key="video_file")
    st.session_state.video_name = st.text_input('–í–≤–µ–¥—ñ—Ç—å –Ω–∞–∑–≤—É –≤—ñ–¥–µ–æ')
    model_size = st.selectbox("Whisper model",["tiny","base","small","medium","large"],index=1)

    if st.button("–û–±—Ä–æ–±–∫–∞"):
        if uploaded_video is not None:
            video_dir = "video"
            Path(video_dir).mkdir(exist_ok=True)
            title = uploaded_video.name
            unique_video_id = f"{title}_{hashlib.md5(url.encode()).hexdigest()[:8]}"
            file_path = os.path.join(video_dir, uploaded_video.name)
            with open(file_path,"wb") as f: 
                f.write(uploaded_video.getbuffer())
            raw = extract_audio_from_video(file_path)            # NumPy array
            wav_path = os.path.join(video_dir, f"{title}.wav")
            sf.write(wav_path, raw, samplerate=16000)
            txt = process_audio(wav_path, model_size, video_dir, title)

        elif url:
            txt, file_path, title, unique_video_id = process_video(url,"video",model_size)
        txt_clean = prepare_text(txt)
        st.session_state.video_context_text['context'] = ""
        if summary and not st.session_state.video_context_text['context']:
            summary = summarise_transcript(txt_clean, create_llm(st.session_state.llm_option))
            st.session_state.video_context_text['context']=summary
        video_meta={"video_id": unique_video_id,
                    "title":title,
                    "url":url,
                    "file_path":file_path, 
                    "upload_date":dt.now().isoformat(),
                    }
        video_json=build_video_json(txt_clean,video_meta,file_path, title)
        dense_ef=create_bge_m3_embeddings()
        retr=VideoHybridRetriever(client=st.session_state.milvus_client, collection_name=collection_name,
                                   dense_embedding_function=dense_ef)
        retr.build_collection()
        for chunk in video_json["chunks"]:
            metadata = {
                **video_json["video_meta"],
                "doc_id":        video_json["doc_id"],
                "original_uuid": video_json["original_uuid"],
                "chunk_id":      chunk["chunk_id"],
                "original_index": chunk["original_index"],
                "file_path":      chunk["file_path"],
                "file_name":      chunk["file_name"],
                "upload_date":    chunk["upload_date"],
            }
            retr.upsert_data(chunk["content"], metadata)
        st.session_state.last_video_json=video_json
        st.session_state.video_processed=True
        st.success("Video processed and uploaded üîÑ")

def chat_video_mode(collection_name, llm_option):
    if st.session_state.video_context_text['context']:
        st.markdown(st.session_state.video_context_text['context'])
    if not st.session_state.messages:
        st.session_state.messages.append({"role": "assistant", "content": "–ü—Ä–∏–≤—ñ—Ç! –Ø –≥–æ—Ç–æ–≤–∏–π –¥–æ —Ä–æ–∑–º–æ–≤–∏. –©–æ –≤–∞—Å —Ü—ñ–∫–∞–≤–∏—Ç—å?"})
         
    for m in st.session_state.messages:
        with st.chat_message(m["role"]): st.markdown(m["content"])
    placeholder = st.empty()

    # –≤–≤–æ–¥ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
 
    if q := st.chat_input("–í–∞—à –∑–∞–ø–∏—Ç"):
     
        st.session_state.messages.append(dict(role="user", content=q))
        with st.chat_message("user"): st.markdown(q)
        with st.chat_message("assistant"):
            st.write("–®—É–∫–∞—é –≤—ñ–¥–ø–æ–≤—ñ–¥—å‚Ä¶")
            dense_ef = create_bge_m3_embeddings()
            retr = VideoHybridRetriever(
            client=st.session_state.milvus_client,
            collection_name=collection_name,
            dense_embedding_function=dense_ef,) 
            retr.build_collection()
            chunks = retr.search(q, mode="hybrid", k=st.session_state.ret_k_results)
            ctx = "\n---\n".join([c["content"] for c in chunks]) if chunks else ""
            user_query = q+"\n---\n"+ctx
            #if llm_option == "–£–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω—É":
            #    chat = [
            #        {"role": "system", "content": "You are useful assistant. Use the info to answer user query. Answer in Ukrainian"},
            #        {"role": "user", "content": user_query}
            #        ]
            #    response = st.session_state.ukr_generator(chat, max_new_tokens=512)
            #    answer = response[0]["generated_text"][-1]["content"]
            if llm_option == "–£–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω—É":
                    # –§–æ—Ä–º—É—î–º–æ —î–¥–∏–Ω–∏–π —Ä—è–¥–æ–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
                    system = UKR_SYSTEM_PROMPT
                    prompt_text = system + "\n\n" + user_query
                    # –í–∏–∫–ª–∏–∫–∞—î–º–æ HuggingFace pipeline, —è–∫–∏–π –æ—á—ñ–∫—É—î —Ä—è–¥–æ–∫
                    gen = st.session_state.ukr_generator(
                            [
                                {"role": "user", "content": user_query}
                            ],
                            max_new_tokens=512,
                            do_sample=False)
                    # –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —Å–ø–∏—Å–æ–∫ –∑ –æ–¥–Ω–∏–º —Å–ª–æ–≤–Ω–∏–∫–æ–º —ñ–∑ –∫–ª—é—á–µ–º "generated_text"
                    answer = gen[0]["generated_text"]
            else:   
                placeholder = st.empty()
                answer = ""
                prompt = create_stream_prompt(st.session_state.system_prompt, q, ctx)
                model = st.session_state.llm_option
                for part in query_ollama(prompt, model):
                    chunk = part["message"]["content"]
                    # –ø–æ‚Äë—Å–∏–º–≤–æ–ª—å–Ω–æ –¥–æ–¥–∞—î–º–æ —Ç–∞ –æ–¥—Ä–∞–∑—É –æ–Ω–æ–≤–ª—é—î–º–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                    for ch in chunk:
                        answer += ch
                        placeholder.text(answer)   # –∞–±–æ .markdown(caption)
            with st.expander("–ü–æ–∫–∞–∑–∞—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"):
                for i in chunks:
                        st.markdown(
                            f"**–§–∞–π–ª:** {i['file_name']}  \n"
                            f"**Chunk ID:** `{i['chunk_id']}`  \n"
                            f"**–î–∞—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è:** {i['upload_date']}  \n"
                            f"**Score:** {i['score']:.4f}  \n\n"
                            f"> {i['content']}",
                        )
            log_interaction(st.session_state.current_mode, q, answer)
            st.session_state.messages.append(dict(role="assistant", content=answer))

def image_mode(collection_name, summary = True):
    st.session_state.current_mode = "image"
    st.subheader("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å")
    uploaded_images = st.file_uploader(
    "–û–±–µ—Ä–∏ –æ–¥–Ω–µ –∞–±–æ –∫—ñ–ª—å–∫–∞ –∑–æ–±—Ä–∞–∂–µ–Ω—å",
    type=["png", "jpg", "jpeg", "webp"],
    accept_multiple_files=True,
    key="image_uploader"
)
    if uploaded_images:
        image_dir = "images"
        if not os.path.exists(image_dir):
            os.makedirs(image_dir)
            st.info(f"–°—Ç–≤–æ—Ä–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é {image_dir} –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω—å")
        
        for img_file in uploaded_images:
            # –ø—Ä–µ–≤—å—é –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
            st.image(img_file)
            pil_img = Image.open(img_file)
            img_b64 = [image_to_base64(pil_img)]
            prompt = IMAGE_DESCRIPTION_SYSTEM_PROMPT
            with st.spinner("–ì–µ–Ω–µ—Ä—É—é –æ–ø–∏—Å‚Ä¶"):
                placeholder = st.empty()
                caption = ""

                # ollama.chat(..., stream=True) –ø–æ–≤–µ—Ä—Ç–∞—î –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä,
                #   —É part["message"]["content"] ‚Äî —á–µ—Ä–≥–æ–≤–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç—É
                for part in query_ollama(prompt, IMAGE_DESCRIPTION_MODEL, img_b64):
                    chunk = part["message"]["content"]
                    # –ø–æ‚Äë—Å–∏–º–≤–æ–ª—å–Ω–æ –¥–æ–¥–∞—î–º–æ —Ç–∞ –æ–¥—Ä–∞–∑—É –æ–Ω–æ–≤–ª—é—î–º–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                    for ch in chunk:
                        caption += ch
                        placeholder.text(caption)   # –∞–±–æ .markdown(caption)
                llm = create_llm(st.session_state.llm_option)
                print(llm, 'llm')
                st.session_state.image_context_text['context'] = ""
                if summary and not st.session_state.image_context_text['context']:
                    summary  = summarise_transcript(caption, llm)
                    summary = remove_think(summary) # –≤–∏–¥–∞–ª—è—î –¥—É–∂–∫–∏ –∑ —Ç–µ–∫—Å—Ç—É
                    st.session_state.image_context_text['context'] = summary
  
            # ---------- —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ----------
            file_ext = os.path.splitext(img_file.name)[1]
            print(file_ext, 'file_ext')
            unique_name = f"{uuid.uuid4().hex}{file_ext}"

            print(unique_name, 'unique_name')
                    
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–æ–ø—ñ—é –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó images
            image_path = os.path.join(image_dir, unique_name)
            with open(image_path, "wb") as f:
                f.write(img_file.getbuffer())
            st.success(f"–ö–æ–ø—ñ—é —Ñ–∞–π–ª—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ {image_path}")
            st.session_state.image_processed = True

            # ---------- –∑–∞–ø–∏—Å—å –≤ Milvus ----------
            raw = build_image_json(caption, image_path, img_file.name)
            if isinstance(raw, dict):
                docs = [raw]
            elif isinstance(raw, list):
                docs = raw
            else:
                raise ValueError("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑ build_json")
            
            print(docs, 'docs')
            
            is_insert = True
            if is_insert:
                dense_ef = create_bge_m3_embeddings()
                standard_retriever = ImageHybridRetriever(
                    client=st.session_state.milvus_client,
                    collection_name=collection_name,
                    dense_embedding_function=dense_ef,)
                standard_retriever.build_collection()          # ‚Üê –¥–æ–¥–∞–ª–∏
                for doc in docs:
                #Added funct
                    existing = standard_retriever.client.query(
                    collection_name=collection_name,
                    filter=f'original_uuid == "{doc["original_uuid"]}"',
                    output_fields=["chunk_id"])
                    existing_ids = {row["chunk_id"] for row in existing}
                #End of adding

                    for chunk in doc["chunks"]:
                        #Added funct
                        if chunk["chunk_id"] in existing_ids:        # –¥—É–±–ª—å ‚Äì –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                            continue
                        #End of adding
                        metadata = {
                            "doc_id":          doc["doc_id"],
                            "original_uuid":  doc["original_uuid"],
                            "chunk_id":       chunk["chunk_id"],
                            "original_index": chunk["original_index"],
                            "content":        chunk["content"],
                            "file_path":      chunk["file_path"],
                            "file_name":      chunk["file_name"],
                            "upload_date":    chunk["upload_date"],
                        }
                        standard_retriever.upsert_data(chunk["content"], metadata)
            st.session_state.image_processed=True

def chat_image_mode(collection_name, llm_option):
    if st.session_state.image_context_text['context']:
        st.markdown(st.session_state.image_context_text['context'])
    if not st.session_state.messages:
        st.session_state.messages.append({"role": "assistant", "content": "–ü—Ä–∏–≤—ñ—Ç! –Ø –≥–æ—Ç–æ–≤–∏–π –¥–æ —Ä–æ–∑–º–æ–≤–∏. –©–æ –≤–∞—Å —Ü—ñ–∫–∞–≤–∏—Ç—å?"})
         
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
    placeholder = st.empty()

    # –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if q := st.chat_input("–í–∞—à –∑–∞–ø–∏—Ç"):
        st.session_state.messages.append(dict(role="user", content=q))
        with st.chat_message("user"): 
            st.markdown(q)
        with st.chat_message("assistant"):
            st.write("–®—É–∫–∞—é –≤—ñ–¥–ø–æ–≤—ñ–¥—å‚Ä¶")
            dense_ef = create_bge_m3_embeddings()

            retriever = ImageHybridRetriever(
                client=st.session_state.milvus_client,
                collection_name=collection_name,
                dense_embedding_function=dense_ef,
            )
            retriever.build_collection()
            results = retriever.search(q, mode="hybrid", k=st.session_state.ret_k_results)
            if not results:
                answer = "–ù–∞ –∂–∞–ª—å, –Ω–µ –∑–Ω–∞–π—à–æ–≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó."
            else:
                ctx = "\n---\n".join([c["content"] for c in results]) if results else ""
                user_query = q+"\n---\n"+ctx
                if llm_option == "–£–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω—É":
                        # –§–æ—Ä–º—É—î–º–æ —î–¥–∏–Ω–∏–π —Ä—è–¥–æ–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
                        system = UKR_SYSTEM_PROMPT
                        prompt_text = system + "\n\n" + user_query
                        # –í–∏–∫–ª–∏–∫–∞—î–º–æ HuggingFace pipeline, —è–∫–∏–π –æ—á—ñ–∫—É—î —Ä—è–¥–æ–∫
                        gen = st.session_state.ukr_generator(
                                [
                                    {"role": "user", "content": user_query}
                                ],
                                max_new_tokens=MAX_TOKENS,
                                do_sample=False)
                        # –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —Å–ø–∏—Å–æ–∫ –∑ –æ–¥–Ω–∏–º —Å–ª–æ–≤–Ω–∏–∫–æ–º —ñ–∑ –∫–ª—é—á–µ–º "generated_text"
                        answer = gen[0]["generated_text"]
                else:
                    placeholder = st.empty()
                    answer = ""
                    prompt = create_stream_prompt(st.session_state.system_prompt, q, ctx)
                    model = st.session_state.llm_option
                    for part in query_ollama(prompt, model):
                        chunk = part["message"]["content"]
                        # –ø–æ‚Äë—Å–∏–º–≤–æ–ª—å–Ω–æ –¥–æ–¥–∞—î–º–æ —Ç–∞ –æ–¥—Ä–∞–∑—É –æ–Ω–æ–≤–ª—é—î–º–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                        for ch in chunk:
                            answer += ch
                            placeholder.text(answer)   # –∞–±–æ .markdown(caption)
                with st.expander("–ü–æ–∫–∞–∑–∞—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"):
                    for i in results:
                            st.markdown(
                                f"**–§–∞–π–ª:** {i['file_name']}  \n"
                                f"**Chunk ID:** `{i['chunk_id']}`  \n"
                                f"**–î–∞—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è:** {i['upload_date']}  \n"
                                f"**Score:** {i['score']:.4f}  \n\n"
                                f"> {i['content']}",
                            )
                log_interaction(st.session_state.current_mode, q, answer)
                st.session_state.messages.append(dict(role="assistant", content=answer))
                

def main_chat(collection_name):
    if "messages" not in st.session_state: 
        st.session_state.messages = []  # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
    # –Ø–∫—â–æ —á–∞—Ç —Ç—ñ–ª—å–∫–∏ —â–æ –∑–∞–ø—É—â–µ–Ω–∏–π, –≤—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ –ø—Ä–∏–≤—ñ—Ç–∞–Ω–Ω—è
    if not st.session_state.messages:
        st.session_state.messages.append({
            "role": "assistant",
            "content": "–ü—Ä–∏–≤—ñ—Ç! –Ø –≤–∞—à —á–∞—Ç‚Äë–∞–≥–µ–Ω—Ç. –Ø –≤–º—ñ—é —à—É–∫–∞—Ç–∏ –ø–æ –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö –≤–µ–∫—Ç–æ—Ä–∞—Ö —É Milvus —ñ –¥–∞–≤–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ. –©–æ –∑–∞–ø–∏—Ç—É—î—Ç–µ?"
        })

    # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –±–ª–æ–∫—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
            st.markdown(msg["content"])  # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    placeholder = st.empty()
    # –í–≤–µ–¥–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    if query := st.chat_input("–í–≤–µ–¥—ñ—Ç—å –≤–∞—à–µ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è...", key="chat_input"):
        # –î–æ–¥–∞–≤–∞–Ω–Ω—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –≤ —ñ—Å—Ç–æ—Ä—ñ—é
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –±–ª–æ–∫—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
            st.markdown(query)  # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–∞–ø–∏—Ç—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞

        # –ó–∞–ø—É—Å–∫ –ø–æ—à—É–∫—É –ø–æ –≤–µ–∫—Ç–æ—Ä–∞—Ö
        with st.chat_message("assistant"):  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –±–ª–æ–∫—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞
            st.write("–®—É–∫–∞—é –≤—ñ–¥–ø–æ–≤—ñ–¥—å...")  # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Å—Ç–∞—Ç—É—Å—É –ø–æ—à—É–∫—É
            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó –≤–±—É–¥–æ–≤—É–≤–∞–Ω–Ω—è
            dense_ef = create_bge_m3_embeddings()
            retriever = HybridRetriever(  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—ñ–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ—à—É–∫–æ–≤–∏–∫–∞
                client=st.session_state.milvus_client,  # –ö–ª—ñ—î–Ω—Ç Milvus
                collection_name=collection_name,  # –ù–∞–∑–≤–∞ –∫–æ–ª–µ–∫—Ü—ñ—ó
                dense_embedding_function=dense_ef,  # –§—É–Ω–∫—Ü—ñ—è –≤–±—É–¥–æ–≤—É–≤–∞–Ω–Ω—è
            )
            retriever.build_collection()
            stats = st.session_state.milvus_client.get_collection_stats(st.session_state.collection_name)
            entity_count = int(stats["row_count"])
            if entity_count == 0:
                answer = "–ù–∞ –∂–∞–ª—å, –Ω–µ –∑–Ω–∞–π—à–æ–≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó."
                metadata = {
                        "doc_id":          'none',
                        "original_uuid":  'none',
                        "chunk_id":      'none',
                        "original_index": 0,
                        "content":        'none',
                        "file_path":      'none',
                        "file_name":      'none',
                        "upload_date":    'none',
                    }

                retriever.upsert_data(answer, metadata)
            results = retriever.search(query, mode="hybrid", k=st.session_state.ret_k_results)
            if not results:  # –Ø–∫—â–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ
                answer = "–ù–∞ –∂–∞–ª—å, –Ω–µ –∑–Ω–∞–π—à–æ–≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó."
            else:
                best = "\n".join(r["content"] for r in results) if results else ""
                user_query = query+"\n---\n"+best  # –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—É –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
                if st.session_state.llm_option == "–£–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω—É":  # –Ø–∫—â–æ –≤–∏–±—Ä–∞–Ω–∞ —É–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω–∞ –º–æ–¥–µ–ª—å
                    chat = [
                        {"role": "system", "content": "You are useful assistant. Use the info to answer user query. Answer in Ukrainian"},
                        {"role": "user", "content": user_query}
                        ]
                    response = st.session_state.ukr_generator(chat, max_new_tokens=512)  # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                    answer = response[0]["generated_text"][-1]["content"]  # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                else:
                # –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –ø—Ä–æ–º–ø—Ç—É —Ç–∞ –≤–∏–∫–ª–∏–∫ LLM
                    placeholder = st.empty()
                    answer = ""
                    prompt = create_stream_prompt(st.session_state.system_prompt, query, best)
                    model = st.session_state.llm_option
                    for part in query_ollama(prompt, model):
                        chunk = part["message"]["content"]
                        # –ø–æ‚Äë—Å–∏–º–≤–æ–ª—å–Ω–æ –¥–æ–¥–∞—î–º–æ —Ç–∞ –æ–¥—Ä–∞–∑—É –æ–Ω–æ–≤–ª—é—î–º–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                        for ch in chunk:
                            answer += ch
                            placeholder.text(answer) 
            with st.expander("–ü–æ–∫–∞–∑–∞—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"):  # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ä–æ–∑–≥–æ—Ä—Ç–∞—î–º–æ–≥–æ –±–ª–æ–∫—É
                    for i in results:
                        st.markdown(
                            f"**–§–∞–π–ª:** {i['file_name']}  \n"  # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É
                            f"**Chunk ID:** `{i['chunk_id']}`  \n"  # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è ID —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
                            f"**–î–∞—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è:** {i['upload_date']}  \n"  # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
                            f"**Score:** {i['score']:.4f}  \n\n"  # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –æ—Ü—ñ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—ñ
                            f"> {i['content']}"  # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤–º—ñ—Å—Ç—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
                            )
            
            st.session_state.messages.append({"role": "assistant", "content": answer})  # –î–æ–¥–∞–≤–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –≤ —ñ—Å—Ç–æ—Ä—ñ—é
            log_interaction(st.session_state.current_mode or "chat", query, answer)  # –õ–æ–≥—É–≤–∞–Ω–Ω—è –≤–∑–∞—î–º–æ–¥—ñ—ó

def document_mode(collection_name, summary):
    uploaded_file = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç", type=['pdf', 'xlsx', 'xls', 'doc', 'docx', 'md'])
    if uploaded_file is not None:
        ext = os.path.splitext(uploaded_file.name)[1].lower()
        if ext in [".xlsx", ".xls", ".csv"]:
            if ext == ".csv":
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            st.dataframe(df.head(10), use_container_width=True)
            preview_text = " ".join(df.astype(str).head(10).values.flatten())
        elif ext == ".pdf":
            reader = PdfReader(uploaded_file)
            first_page_text = reader.pages[0].extract_text() or ""
            preview_text = first_page_text[:1000]
        elif ext in [".docx", ".doc"]:
            docx_obj = DocxDocument(uploaded_file)
            text = "\n".join(p.text for p in docx_obj.paragraphs)
            preview_text = text[:1000]
        else:  # docx, md, txt, etc.
            raw_bytes = uploaded_file.read()
            text = raw_bytes.decode("utf-8", errors="ignore")
            preview_text = text[:1000]
        uploaded_file.seek(0)
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è —Ñ–∞–π–ª—É –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ—ó –Ω–∞–∑–≤–∏
        file_extension = os.path.splitext(uploaded_file.name)[1]
        # –ì–µ–Ω–µ—Ä—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω–µ —ñ–º'—è —Ñ–∞–π–ª—É –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ UUID
        unique_filename = f"{uuid.uuid4().hex}{file_extension}"
        # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤–Ω–∏–π —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –≤ –ø–∞–ø—Ü—ñ data
        file_path = os.path.join("data", unique_filename)
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—É –Ω–∞–∑–≤—É —Ñ–∞–π–ª—É
        original_filename = uploaded_file.name
        
        # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø–∏—Å—É –≤ –±—ñ–Ω–∞—Ä–Ω–æ–º—É —Ä–µ–∂–∏–º—ñ
        with open(file_path, "wb") as f:
            # –ó–∞–ø–∏—Å—É—î–º–æ –≤–º—ñ—Å—Ç –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
            f.write(uploaded_file.getbuffer())
        # –ü–æ–∫–∞–∑—É—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ —É—Å–ø—ñ—à–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        st.success(f"–§–∞–π–ª {original_filename} —É—Å–ø—ñ—à–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —è–∫ {file_path}")
        raw = data_extraction(file_path)
        raw_str = raw.to_csv(index=False) if isinstance(raw, pd.DataFrame) else (
        json.dumps(raw, ensure_ascii=False) if isinstance(raw, dict) else str(raw)
    )
        txt = prepare_text(raw_str)
        st.markdown(f"**–ü–µ—Ä—à—ñ 1000 —Å–∏–º–≤–æ–ª—ñ–≤ —Ñ–∞–π–ª—É:** \n\n {txt[:1000]}")
        st.session_state.document_context_text['context'] = ""
        if summary and not st.session_state.document_context_text['context']:
            summary = summarise_transcript(txt, create_llm(st.session_state.llm_option))
            summary = remove_think(summary) # –≤–∏–¥–∞–ª—è—î –¥—É–∂–∫–∏ –∑ —Ç–µ–∫—Å—Ç—É
            st.session_state.document_context_text['context'] = summary
        raw = build_json(txt, original_filename, file_path)

        if isinstance(raw, dict):
            docs = [raw]
        elif isinstance(raw, list):
            docs = raw
        else:
            raise ValueError("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑ build_json")

        dense_ef = create_bge_m3_embeddings()
        standard_retriever = HybridRetriever(
        client=st.session_state.milvus_client,
        collection_name=collection_name,
        dense_embedding_function=dense_ef,
        )

        is_insert = True
        if is_insert:
            standard_retriever.build_collection()
            for doc in docs:
                existing = standard_retriever.client.query(
                collection_name=collection_name,
                filter=f'original_uuid == "{doc["original_uuid"]}"',
                output_fields=["chunk_id"])
                existing_ids = {row["chunk_id"] for row in existing}
                for chunk in doc["chunks"]:
                    if chunk["chunk_id"] in existing_ids:        # –¥—É–±–ª—å ‚Äì –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        continue
                    metadata = {
                        "doc_id":          doc["doc_id"],
                        "original_uuid":  doc["original_uuid"],
                        "chunk_id":       chunk["chunk_id"],
                        "original_index": chunk["original_index"],
                        "content":        chunk["content"],
                        "file_path":      chunk["file_path"],
                        "file_name":      chunk["file_name"],
                        "upload_date":    chunk["upload_date"],
                    }
                    standard_retriever.upsert_data(chunk["content"], metadata)
        st.session_state.document_processed = True
        st.session_state.document_start = False

        
def chat_document_mode(collection_name, llm_option):
    if st.session_state.document_context_text['context']:
        st.markdown(st.session_state.document_context_text['context'])
    st.session_state.doc_mode = "chat"
    if not st.session_state.messages:
        st.session_state.messages.append({"role": "assistant", "content": "–ü—Ä–∏–≤—ñ—Ç! –Ø –≥–æ—Ç–æ–≤–∏–π –¥–æ —Ä–æ–∑–º–æ–≤–∏. –©–æ –≤–∞—Å —Ü—ñ–∫–∞–≤–∏—Ç—å?"})
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
    placeholder = st.empty()
    # –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if query := st.chat_input("–í–≤–µ–¥—ñ—Ç—å –≤–∞—à–µ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è...", key="document_chat_input"):
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.markdown(query)

        # –°—Ç–∞—Ä—Ç—É–µ–º –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–∞–º
        with st.chat_message("assistant"):
            st.write("–®—É–∫–∞—é –≤—ñ–¥–ø–æ–≤—ñ–¥—å...")
            # –°–æ–∑–¥–∞—ë–º –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –≤–µ–∫—Ç–æ—Ä–æ–≤
            dense_ef = create_bge_m3_embeddings()
            retriever = HybridRetriever(
                client=st.session_state.milvus_client,
                collection_name=collection_name,
                dense_embedding_function=dense_ef,
            )
            retriever.build_collection()          # ‚Üê –¥–æ–¥–∞–ª–∏
            # –ò—â–µ–º 5 –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö —á–∞–Ω–∫–æ–≤
            results = retriever.search(query, mode="hybrid", k=st.session_state.ret_k_results)
            if not results:
                answer = "–ù–∞ –∂–∞–ª—å, –Ω–µ –∑–Ω–∞–π—à–æ–≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó."
            else:
                best = ""
                for i in results:
                    best += i["content"]
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –∏ –≤—ã–∑—ã–≤–∞–µ–º LLM
                prompt = create_prompt(st.session_state.system_prompt)
                if llm_option == "–£–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω—É":
                    # –§–æ—Ä–º—É—î–º–æ —î–¥–∏–Ω–∏–π —Ä—è–¥–æ–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
                    system = UKR_SYSTEM_PROMPT
                    prompt_text = system + "\n\n" + query + "\n---\n" + best
                    # –í–∏–∫–ª–∏–∫–∞—î–º–æ HuggingFace pipeline, —è–∫–∏–π –æ—á—ñ–∫—É—î —Ä—è–¥–æ–∫
                    gen = st.session_state.ukr_generator(prompt_text, max_new_tokens=512, do_sample=False)
                    # –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —Å–ø–∏—Å–æ–∫ –∑ –æ–¥–Ω–∏–º —Å–ª–æ–≤–Ω–∏–∫–æ–º —ñ–∑ –∫–ª—é—á–µ–º "generated_text"
                    answer = gen[0]["generated_text"]
                    st.markdown(f"**Answer:** {answer}")
                    st.markdown(f"**lENG:** {len(answer)}")
                else:   
                    placeholder = st.empty()
                    answer = ""
                    prompt = create_stream_prompt(st.session_state.system_prompt, query, best)
                    model = st.session_state.llm_option
                    for part in query_ollama(prompt, model):
                        chunk = part["message"]["content"]
                        chunk = remove_think(chunk)
                        for ch in chunk:
                            answer += ch
                            placeholder.text(answer)   # –∞–±–æ .markdown(caption)
            
            with st.expander("–ü–æ–∫–∞–∑–∞—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"):
                        for i in results:
                            st.markdown(
                                f"**–§–∞–π–ª:** {i['file_name']}  \n"
                                f"**Chunk ID:** `{i['chunk_id']}`  \n"
                                f"**–î–∞—Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è:** {results[0]['upload_date']}  \n"
                                f"**Score:** {i['score']:.4f}  \n\n"
                                f"> {i['content']}"
                            )
            st.session_state.messages.append({"role": "assistant", "content": answer})
            log_interaction(st.session_state.current_mode or "chat", query, answer)

def create_summary_prompt() -> ChatPromptTemplate:
    return ChatPromptTemplate.from_messages([
        ("system", SUMMARY_SYSTEM_PROMPT),
        ("human", "{text}")
    ])

def summarise_transcript(transcript: str, llm) -> str:
    prompt = create_summary_prompt()
    chain  = create_chain(llm, prompt)    # create_chain = prompt | llm
    response = chain.invoke({"text": transcript})
    return response.content

def on_summarise_video():
    st.session_state.video_summary = True

def on_summarise_audio():
    """–í–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è –ø—Ä–∏ –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—ñ –∫–Ω–æ–ø–∫–∏ ‚Äî —Ä–æ–±–∏—Ç—å summary —ñ –∑–±–µ—Ä—ñ–≥–∞—î –≤ —Å–µ—Å—ñ—ó."""
    st.session_state.audio_summary = True

def on_summarise_image():
    """–í–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è –ø—Ä–∏ –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—ñ –∫–Ω–æ–ø–∫–∏ ‚Äî —Ä–æ–±–∏—Ç—å summary —ñ –∑–±–µ—Ä—ñ–≥–∞—î –≤ —Å–µ—Å—ñ—ó."""
    st.session_state.image_summary = True

def on_summarise_document():
    """–í–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è –ø—Ä–∏ –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—ñ –∫–Ω–æ–ø–∫–∏ ‚Äî —Ä–æ–±–∏—Ç—å summary —ñ –∑–±–µ—Ä—ñ–≥–∞—î –≤ —Å–µ—Å—ñ—ó."""
    st.session_state.document_summary = True
    
